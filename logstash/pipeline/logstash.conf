input {
  file {
    path => "/usr/share/logstash/data/*.json"  # JSON files in the mounted ingestion folder
    start_position => "beginning"              # Read new files from the beginning
    sincedb_path => "/usr/share/logstash/data/sincedb.txt"  # Persistent file to remember ingestion state
    codec => json        # Parse each line as a JSON object
    discover_interval => 15
  }
}

filter {

  # Extract first value from the array
  # Add full path of the file
  mutate {
    add_field => { "filename_path" => "%{path}" }
  }

  ruby {
    code => "
      # Extract filename from full path
      path = event.get('filename_path')
      event.set('filename', File.basename(path)) if path

      # Extract V2Locations lat/lon as [lon, lat] pairs
      lat = event.get('[V2Locations][LocationLatitude]')
      lon = event.get('[V2Locations][LocationLongitude]')

      if lat && lon
        locations = []
        lat.each_with_index do |lat_value, index|
          lon_value = lon[index]
          if lat_value && lon_value
            locations << [lon_value.to_f, lat_value.to_f]
          end
        end
        event.set('location', locations) unless locations.empty?
      end
    "
  }
}

output {
  elasticsearch {
    hosts => ["https://es01:9200"]
    index => "gkg-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    ssl_certificate_verification => true
    cacert => "/usr/share/logstash/certs/ca/ca.crt"
  }
}
