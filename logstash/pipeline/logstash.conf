input {
  file {
    path => "/usr/share/logstash/ingest_json/*.json"  # JSON files in the mounted ingestion folder
    start_position => "beginning"              # Read new files from the beginning
    sincedb_path => "/usr/share/logstash/data/sincedb.txt"  # Persistent file to remember ingestion state
    codec => json                             # Parse each line as a JSON object
    discover_interval => 15
    # Optional: Add a tag to identify events from this input
    # tags => ["gkg_json_input"]
  }
}

filter {
  # --- Existing Ruby filter for location ---
  # (Assumes V2Locations is structured as [V2Locations][LocationLatitude], etc.)
  if [V2Locations] {
      ruby {
        code => "
            lat_array = event.get('[V2Locations][LocationLatitude]') || []
            lon_array = event.get('[V2Locations][LocationLongitude]') || []
            locations = []
            if lat_array.is_a?(Array) && lon_array.is_a?(Array) && lat_array.length == lon_array.length
                lat_array.each_with_index do |lat_value, index|
                    lon_value = lon_array[index]
                    if !lat_value.nil? && !lon_value.nil?
                        begin
                            locations << [lon_value.to_f, lat_value.to_f]
                        rescue ArgumentError, TypeError => e
                            # logger.warn('Failed to convert location coordinate to float', :latitude => lat_value, :longitude => lon_value, :error => e.message)
                        end
                    end
                end
                event.set('location', locations) unless locations.empty?
            end
        "
        id => "extract_lat_lon_pairs"
      }
  } # End of 'if [V2Locations]'


  # --- Mutate filter for NESTED GkgRecordId.Date ---
  # Check if the nested field exists before attempting conversion
  if [GkgRecordId][Date] {   # <-- Check using nested access
    mutate {
      convert => {
        "[GkgRecordId][Date]" => "string"  # <-- Convert using nested access
      }
      id => "convert_gkg_date_to_string"
    }
  } # End of 'if [GkgRecordId][Date]'


  # --- Optional: Remove original complex objects if no longer needed ---
  # mutate {
  #   remove_field => ["[V2Locations]", "[GkgRecordId]"] # Remove parent objects if desired
  #   id => "remove_original_complex_objects"
  # }

} # End of filter block

# ... output block remains the same ...
output {
  elasticsearch {
    hosts => ["https://es01:9200"]
    index => "gkg"
    user => "elastic"
    password => "changeme"
    ssl_certificate_verification => false

    manage_template => true
    template_overwrite => true
    template => "/usr/share/logstash/template.json" # Path to your template file
    # Ensure the template maps GkgRecordId.Date NESTED as a string type
    id => "elasticsearch_gkg_output"
  }
  # stdout { codec => rubydebug } # For debugging
}